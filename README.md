
Predictive Process Monitoring (PPM) allows one to estimate the future behavior of business processes in advance and support operational decisions. Graph neural net- works (GNNs) demonstrate high predictive accuracy in this task, but their explainabil- ity remains critically limited: universal XAI approaches (SHAP, LIME) poorly capture the cyclic and temporal nature of event logs, and existing explainers for GNNs are not suitable for the semantics of edge and node types. This paper presents TAPGExplainer, the first type-sensitive PGExplainer extender specifically adapted to heterogeneous process graphs. The algorithm trains separate masks for each type of the relations, maximizing the mutual information between the explanatory subgraph and the origi- nal prediction. An in-depth evaluation of PPM solutions identified PROPHET as the most suitable model. The TAPGExplainer interpreter was built into the PROPHET model and tested on publicly available process logs. A systematic comparative analy- sis with state-of-the-art explainers (GNNExplainer, SubgraphX, original PGExplainer) was performed, showing a steady improvement in interpretability, compactness, and speed of explanation generation on all datasets. This work bridges the gap between the high accuracy of graph predictors and the requirement for their transparency.
