{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bea8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/Next_Activity_GNN\n",
      "/home/sebdis/ProcessMining/Next_Activity_GNN\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import dirname\n",
    "\n",
    "root_path = dirname(dirname(os.getcwd()))\n",
    "print(root_path)\n",
    "import sys\n",
    "\n",
    "sys.path.append(root_path + \"/DuongNA/2_Scripts/\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "\n",
    "from Event_log_processing_utils import (\n",
    "    Extract_trace_and_temporal_features,\n",
    "    Extract_prefix,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_dir = root_path + \"/DuongNA/1_Data/\"\n",
    "project_dir = root_path + \"/DuongNA/\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fccf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c7935",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac6293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"Helpdesk\"\n",
    "# data_name = \"env_permit\"\n",
    "# data_name = \"BPI_Challenge_2012_A\"\n",
    "# data_name = \"BPI_Challenge_2012_O\"\n",
    "# data_name = \"BPI_Challenge_2012_W_Complete\"\n",
    "# data_name = \"BPI_Challenge_2013_closed_problems\"\n",
    "# data_name = \"BPI_Challenge_2013_incidents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff93497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = pd.read_csv(data_dir + data_name + \"_processed_all.csv\")\n",
    "tab_train = pd.read_csv(data_dir + data_name + \"_processed_train.csv\")\n",
    "tab_valid = pd.read_csv(data_dir + data_name + \"_processed_valid.csv\")\n",
    "tab_test = pd.read_csv(data_dir + data_name + \"_processed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d35e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cases: 4552\n",
      "num_activities: 10\n",
      "num_events: 21197\n",
      "avg_case_len: 4.66\n",
      "max_case_len: 15\n",
      "avg_case_duration: 40.85\n",
      "max_case_duration: 59.99\n",
      "min_case_duration: 30.63\n",
      "variants: 207\n"
     ]
    }
   ],
   "source": [
    "# Statistics of the dataset\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(\n",
    "    tab_all\n",
    ")\n",
    "print(\"num_cases: {}\".format(len(tab_all[\"Case_ID\"].unique())))\n",
    "print(\"num_activities: {}\".format(len(tab_all[\"Activity\"].unique())))\n",
    "print(\"num_events: {}\".format(len(tab_all)))\n",
    "avglen = round(np.mean([len(x) for x in lines]), 2)\n",
    "print(\"avg_case_len: {}\".format(avglen))\n",
    "maxlen = max([len(x) for x in lines])  # find maximum line size\n",
    "print(\"max_case_len: {}\".format(maxlen))\n",
    "print(\n",
    "    \"avg_case_duration: {}\".format(\n",
    "        round(np.mean([sublist[-1] for sublist in lines_t2]) / 86400, 2)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"max_case_duration: {}\".format(\n",
    "        round(max([sublist[-1] for sublist in lines_t2]) / 86400, 2)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"min_case_duration: {}\".format(\n",
    "        round(min([sublist[-1] for sublist in lines_t2]) / 86400, 2)\n",
    "    )\n",
    ")\n",
    "list_unique_line = []\n",
    "for line in lines:\n",
    "    if line not in list_unique_line:\n",
    "        list_unique_line.append(line)\n",
    "print(\"variants: {}\".format(len(list_unique_line)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540c868",
   "metadata": {},
   "source": [
    "## 2. Prepare inputs and outputs for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55090026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_X_Y_remaining_time(\n",
    "    tab, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen\n",
    "):\n",
    "    lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(\n",
    "        tab\n",
    "    )\n",
    "    prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)\n",
    "    num_samples = len(prefixes[0])\n",
    "    #     [sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4], [next_ope, next_ope_t, end_ope_t]\n",
    "    print(\"Vectorization...\")\n",
    "    num_features = len(list_activities) + 5  # 1 order feature + 4 temporal features\n",
    "    print(\"num features: {}\".format(num_features))\n",
    "    X = np.zeros((num_samples, maxlen, num_features), dtype=np.float32)\n",
    "    Y = np.zeros((num_samples, len(list_activities)), dtype=np.float32)\n",
    "    for i, sentence in enumerate(prefixes[0]):\n",
    "\n",
    "        leftpad = maxlen - len(sentence)\n",
    "        end_t = outputs[2][i]\n",
    "        sentence_t = prefixes[1][i]\n",
    "        sentence_t2 = prefixes[2][i]\n",
    "        sentence_t3 = prefixes[3][i]\n",
    "        sentence_t4 = prefixes[4][i]\n",
    "        one_hot_act_matrix = encoder.transform(\n",
    "            np.array(sentence).reshape((len(sentence), 1))\n",
    "        ).toarray()\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t + leftpad, : len(list_activities)] = one_hot_act_matrix[t, :]\n",
    "            X[i, t + leftpad, len(list_activities)] = (\n",
    "                t + 1\n",
    "            )  # order of the activity in the sequence {1,...,maxlen}\n",
    "            X[i, t + leftpad, len(list_activities) + 1] = sentence_t[t] / divisor\n",
    "            X[i, t + leftpad, len(list_activities) + 2] = sentence_t2[t] / divisor2\n",
    "            X[i, t + leftpad, len(list_activities) + 3] = sentence_t3[t] / 86400\n",
    "            X[i, t + leftpad, len(list_activities) + 4] = sentence_t4[t] / 7\n",
    "        # print(encoder.transform(np.array([[outputs[0][i]]])).toarray())\n",
    "        Y[i] = encoder.transform(np.array([[outputs[0][i]]])).toarray()[0]\n",
    "        # break\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfac5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 744287.3818275507\n",
      "divisor2: 1111494.5871693576\n",
      "divisor_rt: 2966515.512665685\n",
      "Vectorization...\n",
      "num features: 15\n",
      "Vectorization...\n",
      "num features: 15\n",
      "Vectorization...\n",
      "num features: 15\n"
     ]
    }
   ],
   "source": [
    "list_activities = list(tab_all[\"Activity\"].unique())\n",
    "num_features = len(list_activities) + 5\n",
    "# creating instance of one-hot-encoder and fit on the whole dataset\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder.fit(np.array(list_activities).reshape((len(list_activities), 1)))\n",
    "\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(\n",
    "    tab_all\n",
    ")\n",
    "maxlen = max([len(x) for x in lines])  # find maximum line size\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(\n",
    "    tab_train\n",
    ")\n",
    "divisor = np.mean(\n",
    "    [item for sublist in lines_t for item in sublist]\n",
    ")  # average time between events\n",
    "print(\"divisor: {}\".format(divisor))\n",
    "divisor2 = np.mean(\n",
    "    [item for sublist in lines_t2 for item in sublist]\n",
    ")  # average time between current and first events\n",
    "print(\"divisor2: {}\".format(divisor2))\n",
    "prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)\n",
    "divisor_rt = np.mean(outputs[2])\n",
    "print(\"divisor_rt: {}\".format(divisor_rt))\n",
    "# Train data\n",
    "X_train, Y_train = Prepare_X_Y_remaining_time(\n",
    "    tab_train, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen\n",
    ")\n",
    "# Valid data\n",
    "X_valid, Y_valid = Prepare_X_Y_remaining_time(\n",
    "    tab_valid, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen\n",
    ")\n",
    "# Test data\n",
    "X_test, Y_test = Prepare_X_Y_remaining_time(\n",
    "    tab_test, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75820a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventLogData(Dataset):\n",
    "    def __init__(self, input_x, output):\n",
    "        self.X = input_x\n",
    "        self.y = output\n",
    "        self.y = self.y.to(torch.float32)\n",
    "\n",
    "    # get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # get a row at a particular index in the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d80602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    EventLogData(torch.tensor(X_valid), torch.tensor(Y_valid)),\n",
    "    batch_size=X_valid.shape[0],\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    EventLogData(torch.tensor(X_test), torch.tensor(Y_test)),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dcaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to keep track of the metrics of the classification process\n",
    "class ClassificationMetrics:\n",
    "\n",
    "    # Constructor takes the number of classes, in our case 20\n",
    "    def __init__(self, num_classes=20):\n",
    "        self.num_classes = num_classes\n",
    "        # Initialize a confusion matrix\n",
    "        self.C = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "    # Update the confusion matrix with the new scores\n",
    "    def add(self, yp, yt):\n",
    "        # yp: 1D tensor with predictions\n",
    "        # yt: 1D tensor with ground-truth targets\n",
    "        yp = yp.to(\"cpu\")\n",
    "        yt = yt.to(\"cpu\")\n",
    "        with torch.no_grad():  # We require no computation graph\n",
    "            self.C += (\n",
    "                (yt * self.C.shape[1] + yp)\n",
    "                .bincount(minlength=self.C.numel())\n",
    "                .view(self.C.shape)\n",
    "                .float()\n",
    "            )\n",
    "\n",
    "    def clear(self):\n",
    "        # We set the confusion matrix to zero\n",
    "        self.C.zero_()\n",
    "\n",
    "    # Computes the global accuracy\n",
    "    def acc(self):\n",
    "        return self.C.diag().sum().item() / self.C.sum()\n",
    "\n",
    "    # Computes the class-averaged accuracy\n",
    "    def mAcc(self):\n",
    "        return (self.C.diag() / self.C.sum(-1)).mean().item()\n",
    "\n",
    "    # Computers the class-averaged Intersection over Union\n",
    "    def mIoU(self):\n",
    "        return (\n",
    "            (self.C.diag() / (self.C.sum(0) + self.C.sum(1) - self.C.diag()))\n",
    "            .mean()\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "    # Returns the confusion matrix\n",
    "    def confusion_matrix(self):\n",
    "        return self.C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14456b99",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter tuning with Ax package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc7cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM class\n",
    "class LSTM_direct(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object\n",
    "    def __init__(self, parameterization):\n",
    "        super(LSTM_direct, self).__init__()\n",
    "        self.hidden_dim = parameterization.get(\"neurons\", 40)\n",
    "        self.num_layers = parameterization.get(\"layers\", 1)\n",
    "        self.droppout_prob = parameterization.get(\"dropout\", 0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.droppout_prob,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, len(list_activities))\n",
    "\n",
    "    # Progresses data across layers\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        init_states, init_cells = self.init_hidden(batch_size)\n",
    "        init_states = init_states.to(x.device)\n",
    "        init_cells = init_cells.to(x.device)\n",
    "        _, (last_Hidden_State, _) = self.lstm(x, (init_states, init_cells))\n",
    "        out = self.fc(last_Hidden_State[-1])\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        init_cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            init_states.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "            init_cells.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "        return torch.stack(init_states, dim=0), torch.stack(\n",
    "            init_cells, dim=0\n",
    "        )  # (num_layers, B, H)\n",
    "\n",
    "\n",
    "def net_train(\n",
    "    net, train_loader, valid_loader, parameters, dtype, device, early_stop_patience\n",
    "):\n",
    "    net.to(dtype=dtype, device=device)\n",
    "    min_delta = 0\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(), lr=parameters.get(\"lr\", 0.001)\n",
    "    )  # 0.001 is used if no lr is specified\n",
    "    num_epochs = 100  # Play around with epoch number\n",
    "    metric_tracker = ClassificationMetrics(len(list_activities))\n",
    "    # Train Network\n",
    "    not_improved_count = 0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        training_loss = 0\n",
    "        num_train = 0\n",
    "\n",
    "        metric_tracker.clear()\n",
    "        for inputs, labels in train_loader:\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            labels = torch.tensor([torch.max(yi, 0)[1] for yi in labels])\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            output = net(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            num_train += 1\n",
    "            _, preds = torch.max(output, 1)\n",
    "            preds = preds.to(device)\n",
    "            metric_tracker.add(preds, labels)\n",
    "        train_acc = metric_tracker.acc()\n",
    "        metric_tracker.clear()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            num_valid = 0\n",
    "            validation_loss = 0\n",
    "            for i, (inputs, targets) in enumerate(valid_loader):\n",
    "                inputs, targets = inputs.to(device), torch.tensor(\n",
    "                    [torch.max(yi, 0)[1] for yi in targets]\n",
    "                ).to(device)\n",
    "                yhat_valid = net(inputs)\n",
    "                loss_valid = criterion(yhat_valid, targets)\n",
    "                validation_loss += loss_valid.item()\n",
    "                num_valid += 1\n",
    "                _, preds = torch.max(yhat_valid, 1)\n",
    "                preds = preds.to(device)\n",
    "                metric_tracker.add(preds, targets)\n",
    "        val_acc = metric_tracker.acc()\n",
    "\n",
    "        avg_training_loss = training_loss / num_train\n",
    "        avg_validation_loss = validation_loss / num_valid\n",
    "\n",
    "        print(\n",
    "            \"Epoch: {}, Training Loss | Acc: {:.3f} {:.3f}, Validation Loss | ACC : {:.3f} {:.3f}\".format(\n",
    "                epoch, avg_training_loss, train_acc, avg_validation_loss, val_acc\n",
    "            )\n",
    "        )\n",
    "        if epoch == 0:\n",
    "            best_loss = avg_validation_loss\n",
    "            best_model = copy.deepcopy(net)\n",
    "        else:\n",
    "            if best_loss - avg_validation_loss >= min_delta:\n",
    "                best_model = copy.deepcopy(net)\n",
    "                best_loss = avg_validation_loss\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "        # Early stopping\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Training time:\", training_time)\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def lstm_direct_evaluate(net, data_loader, dtype, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            targets = torch.tensor([torch.max(yi, 0)[1] for yi in targets]).to(\n",
    "                device=device\n",
    "            )\n",
    "            outputs = net(inputs)\n",
    "            loss += criterion(outputs, targets)\n",
    "            total += 1\n",
    "    return loss.item() / total\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization):\n",
    "\n",
    "    # constructing a new training data loader allows us to tune the batch size\n",
    "    train_loader = DataLoader(\n",
    "        EventLogData(torch.tensor(X_train), torch.tensor(Y_train)),\n",
    "        batch_size=parameterization.get(\"batchsize\", 32),\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Get neural net\n",
    "    untrained_net = LSTM_direct(parameterization)\n",
    "    # train\n",
    "    trained_net = net_train(\n",
    "        net=untrained_net,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        parameters=parameterization,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "        early_stop_patience=10,\n",
    "    )\n",
    "\n",
    "    # return the accuracy of the model as it was trained in this run\n",
    "    return lstm_direct_evaluate(\n",
    "        net=trained_net,\n",
    "        data_loader=valid_loader,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "488bd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf66d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-07 11:14:34] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[ChoiceParameter(name='neurons', parameter_type=INT, values=[40, 60, 80, 100], is_ordered=True, sort_values=True), ChoiceParameter(name='layers', parameter_type=INT, values=[2, 3, 4, 5], is_ordered=True, sort_values=True), RangeParameter(name='lr', parameter_type=FLOAT, range=[0.0001, 0.1], log_scale=True), ChoiceParameter(name='batchsize', parameter_type=INT, values=[16, 32, 64], is_ordered=True, sort_values=True), RangeParameter(name='dropout', parameter_type=FLOAT, range=[0.0, 0.5])], parameter_constraints=[]).\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=5 num_trials=None use_batch_trials=False\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=10\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=10\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 11-07 11:14:34] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 10 trials, BoTorch for subsequent trials]). Iterations after 10 will take longer to generate due to model-fitting.\n",
      "[INFO 11-07 11:14:34] ax.service.managed_loop: Started full optimization with 1 steps.\n",
      "[INFO 11-07 11:14:34] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss | Acc: 1.144 0.580, Validation Loss | ACC : 0.630 0.789\n",
      "Epoch: 1, Training Loss | Acc: 0.600 0.818, Validation Loss | ACC : 0.638 0.790\n",
      "Epoch: 2, Training Loss | Acc: 0.567 0.823, Validation Loss | ACC : 0.603 0.790\n",
      "Epoch: 3, Training Loss | Acc: 0.553 0.825, Validation Loss | ACC : 0.617 0.789\n",
      "Epoch: 4, Training Loss | Acc: 0.549 0.824, Validation Loss | ACC : 0.578 0.791\n",
      "Epoch: 5, Training Loss | Acc: 0.545 0.824, Validation Loss | ACC : 0.626 0.789\n",
      "Epoch: 6, Training Loss | Acc: 0.539 0.825, Validation Loss | ACC : 0.591 0.790\n",
      "Epoch: 7, Training Loss | Acc: 0.539 0.824, Validation Loss | ACC : 0.594 0.791\n",
      "Epoch: 8, Training Loss | Acc: 0.536 0.824, Validation Loss | ACC : 0.577 0.795\n",
      "Epoch: 9, Training Loss | Acc: 0.536 0.824, Validation Loss | ACC : 0.635 0.789\n",
      "Epoch: 10, Training Loss | Acc: 0.536 0.825, Validation Loss | ACC : 0.600 0.794\n",
      "Epoch: 11, Training Loss | Acc: 0.534 0.825, Validation Loss | ACC : 0.610 0.793\n",
      "Epoch: 12, Training Loss | Acc: 0.533 0.824, Validation Loss | ACC : 0.615 0.790\n",
      "Epoch: 13, Training Loss | Acc: 0.528 0.826, Validation Loss | ACC : 0.623 0.788\n",
      "Epoch: 14, Training Loss | Acc: 0.527 0.826, Validation Loss | ACC : 0.598 0.792\n",
      "Epoch: 15, Training Loss | Acc: 0.529 0.825, Validation Loss | ACC : 0.643 0.786\n",
      "Epoch: 16, Training Loss | Acc: 0.523 0.828, Validation Loss | ACC : 0.591 0.797\n",
      "Epoch: 17, Training Loss | Acc: 0.526 0.826, Validation Loss | ACC : 0.639 0.788\n",
      "Epoch: 18, Training Loss | Acc: 0.524 0.826, Validation Loss | ACC : 0.604 0.787\n",
      "Validation performance didn't improve for 10 epochs. Training stops.\n",
      "Training time: 8.893874406814575\n",
      "{'neurons': 60, 'layers': 2, 'lr': 0.0017885402417238043, 'batchsize': 32, 'dropout': 0.34408897161483765}\n",
      "{'CrossEntropy loss': 0.5765691995620728}\n"
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"neurons\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [40, 60, 80, 100],\n",
    "            \"value_type\": \"int\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"layers\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [2, 3, 4, 5],\n",
    "            \"value_type\": \"int\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"lr\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [1e-4, 0.1],\n",
    "            \"value_type\": \"float\",\n",
    "            \"log_scale\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"batchsize\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [16, 32, 64],\n",
    "            \"value_type\": \"int\",\n",
    "        },\n",
    "        {\"name\": \"dropout\", \"type\": \"range\", \"bounds\": [0, 0.5], \"value_type\": \"float\"},\n",
    "    ],\n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name=\"CrossEntropy loss\",\n",
    "    minimize=True,\n",
    "    random_seed=23,\n",
    "    total_trials=1,\n",
    ")\n",
    "\n",
    "print(best_parameters)\n",
    "means, covariances = values\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b67f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_objectives = np.array(\n",
    "    [[trial.objective_mean for trial in experiment.trials.values()]]\n",
    ")\n",
    "\n",
    "best_objective_plot = optimization_trace_single_method(\n",
    "    y=np.minimum.accumulate(best_objectives, axis=1),\n",
    "    title=\"Model performance vs. # of iterations\",\n",
    "    ylabel=\"CrossEntropy loss\",\n",
    ")\n",
    "# render(best_objective_plot)\n",
    "\n",
    "# render(plot_contour(model=model, param_x='dropout', param_y='lr', metric_name='MAE loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e8c238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm(name='0_0', parameters={'neurons': 60, 'layers': 2, 'lr': 0.0017885402417238043, 'batchsize': 32, 'dropout': 0.34408897161483765})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = experiment.fetch_data()\n",
    "df = data.df\n",
    "best_arm_name = df.arm_name[df[\"mean\"] == df[\"mean\"].min()].values[0]\n",
    "best_arm = experiment.arms_by_name[best_arm_name]\n",
    "best_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441fdbb",
   "metadata": {},
   "source": [
    "## 4. Re-Train model with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c8f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM class\n",
    "class LSTM_direct_model(nn.Module):\n",
    "    #  Determine what layers and their order in CNN object\n",
    "    def __init__(self, hidden_dim, num_layers, droppout_prob):\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        super(LSTM_direct_model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=droppout_prob,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, len(list_activities))\n",
    "\n",
    "    # Progresses data across layers\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        init_states, init_cells = self.init_hidden(batch_size)\n",
    "        init_states = init_states.to(x.device)\n",
    "        init_cells = init_cells.to(x.device)\n",
    "        lstm_output, (last_Hidden_State, last_Cell_State) = self.lstm(\n",
    "            x, (init_states, init_cells)\n",
    "        )\n",
    "        out = self.fc(last_Hidden_State[-1])\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        init_cells = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "            init_cells.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "        return torch.stack(init_states, dim=0), torch.stack(\n",
    "            init_cells, dim=0\n",
    "        )  # (num_layers, B, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f886268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # best_arm.parameters['batchsize']\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EventLogData(torch.tensor(X_train), torch.tensor(Y_train)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07b9d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"_Tax_LSTM_direct\"\n",
    "save_folder = project_dir + \"/5_Output_files/Next_Activity/\" + data_name + model_name\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ea5af4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch: 0, Training Loss | Acc: 1.550 0.481, Validation Loss | ACC : 1.088 0.620\n",
      "Epoch: 1, Training Loss | Acc: 1.128 0.627, Validation Loss | ACC : 0.834 0.815\n",
      "Epoch: 2, Training Loss | Acc: 0.879 0.706, Validation Loss | ACC : 0.702 0.831\n",
      "Epoch: 3, Training Loss | Acc: 0.716 0.781, Validation Loss | ACC : 0.692 0.791\n",
      "Epoch: 4, Training Loss | Acc: 0.640 0.818, Validation Loss | ACC : 0.658 0.791\n",
      "Epoch: 5, Training Loss | Acc: 0.602 0.824, Validation Loss | ACC : 0.624 0.791\n",
      "Epoch: 6, Training Loss | Acc: 0.582 0.825, Validation Loss | ACC : 0.613 0.791\n",
      "Epoch: 7, Training Loss | Acc: 0.566 0.826, Validation Loss | ACC : 0.611 0.791\n",
      "Epoch: 8, Training Loss | Acc: 0.558 0.825, Validation Loss | ACC : 0.626 0.791\n",
      "Epoch: 9, Training Loss | Acc: 0.551 0.824, Validation Loss | ACC : 0.629 0.791\n",
      "Epoch: 10, Training Loss | Acc: 0.554 0.825, Validation Loss | ACC : 0.611 0.791\n",
      "Epoch: 11, Training Loss | Acc: 0.552 0.825, Validation Loss | ACC : 0.612 0.791\n",
      "Epoch: 12, Training Loss | Acc: 0.543 0.825, Validation Loss | ACC : 0.631 0.791\n",
      "Epoch: 13, Training Loss | Acc: 0.540 0.825, Validation Loss | ACC : 0.593 0.794\n",
      "Epoch: 14, Training Loss | Acc: 0.546 0.825, Validation Loss | ACC : 0.615 0.791\n",
      "Epoch: 15, Training Loss | Acc: 0.541 0.825, Validation Loss | ACC : 0.613 0.792\n",
      "Epoch: 16, Training Loss | Acc: 0.535 0.825, Validation Loss | ACC : 0.585 0.797\n",
      "Epoch: 17, Training Loss | Acc: 0.534 0.825, Validation Loss | ACC : 0.607 0.792\n",
      "Epoch: 18, Training Loss | Acc: 0.540 0.825, Validation Loss | ACC : 0.596 0.793\n",
      "Epoch: 19, Training Loss | Acc: 0.537 0.825, Validation Loss | ACC : 0.616 0.791\n",
      "Epoch: 20, Training Loss | Acc: 0.536 0.825, Validation Loss | ACC : 0.597 0.794\n",
      "Epoch: 21, Training Loss | Acc: 0.529 0.825, Validation Loss | ACC : 0.635 0.791\n",
      "Epoch: 22, Training Loss | Acc: 0.530 0.825, Validation Loss | ACC : 0.596 0.793\n",
      "Epoch: 23, Training Loss | Acc: 0.529 0.825, Validation Loss | ACC : 0.612 0.791\n",
      "Epoch: 24, Training Loss | Acc: 0.530 0.825, Validation Loss | ACC : 0.608 0.792\n",
      "Epoch: 25, Training Loss | Acc: 0.530 0.824, Validation Loss | ACC : 0.621 0.791\n",
      "Epoch: 26, Training Loss | Acc: 0.527 0.825, Validation Loss | ACC : 0.596 0.794\n",
      "Epoch: 27, Training Loss | Acc: 0.531 0.826, Validation Loss | ACC : 0.595 0.794\n",
      "Epoch: 28, Training Loss | Acc: 0.526 0.825, Validation Loss | ACC : 0.605 0.792\n",
      "Epoch: 29, Training Loss | Acc: 0.528 0.824, Validation Loss | ACC : 0.602 0.793\n",
      "Epoch: 30, Training Loss | Acc: 0.529 0.825, Validation Loss | ACC : 0.622 0.791\n",
      "Epoch: 31, Training Loss | Acc: 0.537 0.825, Validation Loss | ACC : 0.620 0.791\n",
      "Epoch: 32, Training Loss | Acc: 0.528 0.825, Validation Loss | ACC : 0.595 0.794\n",
      "Epoch: 33, Training Loss | Acc: 0.531 0.825, Validation Loss | ACC : 0.598 0.794\n",
      "Epoch: 34, Training Loss | Acc: 0.526 0.825, Validation Loss | ACC : 0.622 0.791\n",
      "Epoch: 35, Training Loss | Acc: 0.525 0.824, Validation Loss | ACC : 0.601 0.793\n",
      "Epoch: 36, Training Loss | Acc: 0.524 0.824, Validation Loss | ACC : 0.596 0.794\n",
      "Validation performance didn't improve for 20 epochs. Training stops.\n",
      "Training time: 10.473800897598267\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 40  #  best_arm.parameters['neurons']\n",
    "num_layers = 1  # best_arm.parameters['layers']\n",
    "droppout_prob = 0.2  #  best_arm.parameters['dropout']\n",
    "lr_value = 0.001  # best_arm.parameters['lr']\n",
    "min_delta = 0\n",
    "num_epochs = 100\n",
    "early_stop_patience = 20\n",
    "num_runs = 1\n",
    "# Define loss and optimizer\n",
    "for run in range(num_runs):\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "    model = LSTM_direct_model(hidden_dim, num_layers, droppout_prob)\n",
    "    model.to(dtype=dtype, device=device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr_value)\n",
    "    epochs_plt = []\n",
    "    cross_entropy_plt = []\n",
    "    valid_loss_plt = []\n",
    "    not_improved_count = 0\n",
    "    # Train Network\n",
    "    start_time = time.time()\n",
    "    metric_tracker = ClassificationMetrics(len(list_activities))\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        num_train = 0\n",
    "        metric_tracker.clear()\n",
    "        for inputs, labels in train_loader:\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            labels = torch.tensor([torch.max(yi, 0)[1] for yi in labels])\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            num_train += 1\n",
    "            _, preds = torch.max(output, 1)\n",
    "            preds = preds.to(device)\n",
    "            metric_tracker.add(preds, labels)\n",
    "        train_acc = metric_tracker.acc()\n",
    "        metric_tracker.clear()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            num_valid = 0\n",
    "            validation_loss = 0\n",
    "            for i, (inputs, targets) in enumerate(valid_loader):\n",
    "                inputs, targets = inputs.to(device), torch.tensor(\n",
    "                    [torch.max(yi, 0)[1] for yi in targets]\n",
    "                ).to(device)\n",
    "                yhat_valid = model(inputs)\n",
    "                loss_valid = criterion(yhat_valid, targets)\n",
    "                validation_loss += loss_valid.item()\n",
    "                num_valid += 1\n",
    "                _, preds = torch.max(yhat_valid, 1)\n",
    "                preds = preds.to(device)\n",
    "                metric_tracker.add(preds, targets)\n",
    "        val_acc = metric_tracker.acc()\n",
    "\n",
    "        avg_training_loss = training_loss / num_train\n",
    "        avg_validation_loss = validation_loss / num_valid\n",
    "        print(\n",
    "            \"Epoch: {}, Training Loss | Acc: {:.3f} {:.3f}, Validation Loss | ACC : {:.3f} {:.3f}\".format(\n",
    "                epoch, avg_training_loss, train_acc, avg_validation_loss, val_acc\n",
    "            )\n",
    "        )\n",
    "        epochs_plt.append(epoch + 1)\n",
    "        cross_entropy_plt.append(avg_training_loss)\n",
    "        valid_loss_plt.append(avg_validation_loss)\n",
    "        if epoch == 0:\n",
    "            best_loss = avg_validation_loss\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"{}/best_model_run_{}.pt\".format(save_folder, run + 1),\n",
    "            )\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            if best_loss - avg_validation_loss >= min_delta:\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    \"{}/best_model_run_{}.pt\".format(save_folder, run + 1),\n",
    "                )\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_loss = avg_validation_loss\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "        # Early stopping\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Training time:\", training_time)\n",
    "    filepath = \"{}/Loss_\".format(save_folder) + data_name + \"_run{}.txt\".format(run)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        for item in zip(epochs_plt, cross_entropy_plt, valid_loss_plt):\n",
    "            file.write(\"{}\\n\".format(item))\n",
    "        file.write(\"Running time: {}\\n\".format(training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f79583",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a879171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(\n",
    "    tab_test\n",
    ")\n",
    "prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03ff3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    err_dict = {}\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        metric_tracker = ClassificationMetrics(num_classes=len(list_activities))\n",
    "        for i, (inputs, targets) in enumerate(test_loader):\n",
    "            metric_tracker.clear()\n",
    "            prefix_len = len(prefixes[0][i])\n",
    "\n",
    "            # inputs = [[sub_item.to(dtype=torch.float32, device=device) for sub_item in item] for item in inputs]\n",
    "            # targets = torch.tensor(targets).to(device=device)\n",
    "            inputs = inputs.to(device)\n",
    "            targets = torch.tensor([torch.max(yi, 0)[1] for yi in targets]).to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # loss_mape = torch.abs((targets - yhat)/targets)*100\n",
    "            # criterion = nn.CrossEntropyLoss()\n",
    "            # loss_mae = criterion(yhat,targets).item()\n",
    "\n",
    "            metric_tracker.add(torch.max(outputs, 1)[1], targets)\n",
    "\n",
    "            if prefix_len not in err_dict.keys():\n",
    "                err_dict[prefix_len] = [metric_tracker.acc()]\n",
    "            else:\n",
    "                err_dict[prefix_len].append(metric_tracker.acc())\n",
    "    return err_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "111f4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/Next_Activity_GNN/DuongNA//5_Output_files/Next_Activity/Helpdesk_Tax_LSTM_direct\n",
      "Run: 1\n",
      "{2: [tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.)], 3: [tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.)], 4: [tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.)], 5: [tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.)], 6: [tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.)], 7: [tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.), tensor(1.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.)], 8: [tensor(0.), tensor(1.), tensor(1.), tensor(1.)], 9: [tensor(1.)], 10: [tensor(0.)], 11: [tensor(0.)], 12: [tensor(0.)], 13: [tensor(1.)]}\n"
     ]
    }
   ],
   "source": [
    "err_total_dict = {}\n",
    "print(save_folder)\n",
    "for run in range(num_runs):\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "    trained_model = LSTM_direct_model(hidden_dim, num_layers, droppout_prob)\n",
    "    trained_model = trained_model.to(device)\n",
    "    trained_model.load_state_dict(\n",
    "        torch.load(\n",
    "            \"{}/best_model_run_{}.pt\".format(save_folder, run + 1),\n",
    "            map_location=torch.device(device),\n",
    "        )\n",
    "    )\n",
    "    err_dict = evaluate_model(trained_model)\n",
    "    print(err_dict)\n",
    "    for key in err_dict.keys():\n",
    "        err = torch.mean(torch.tensor(err_dict[key]), axis=0)\n",
    "        if key in err_total_dict.keys():\n",
    "            err_total_dict[key].append(torch.tensor(err))\n",
    "        else:\n",
    "            err_total_dict[key] = [torch.tensor(err)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c63466",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_dict = {}\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "    key = len(prefixes[0][i])\n",
    "    if key in num_samples_dict.keys():\n",
    "        num_samples_dict[key] += 1\n",
    "    else:\n",
    "        num_samples_dict[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7747a280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefix length</th>\n",
       "      <th>Num samples</th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1518</td>\n",
       "      <td>0.571146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.646207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>684</td>\n",
       "      <td>0.821637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>0.699422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>0.779412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prefix length  Num samples  Accuracy(%)\n",
       "0               2         1518     0.571146\n",
       "1               3         1450     0.646207\n",
       "2               4          684     0.821637\n",
       "3               5          173     0.699422\n",
       "4               6           68     0.779412\n",
       "5               7           20     0.900000\n",
       "6               8            4     0.750000\n",
       "7               9            1     1.000000\n",
       "8              10            1     0.000000\n",
       "9              11            1     0.000000\n",
       "10             12            1     0.000000\n",
       "11             13            1     1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_prefix_len = []\n",
    "list_num_samples = []\n",
    "list_accuracy = []\n",
    "\n",
    "for key, value in err_total_dict.items():\n",
    "    list_prefix_len.append(key)\n",
    "    list_num_samples.append(num_samples_dict[key])\n",
    "    list_accuracy.append(value[0].item())\n",
    "\n",
    "tab_result = pd.DataFrame(\n",
    "    {\n",
    "        \"Prefix length\": list_prefix_len,\n",
    "        \"Num samples\": list_num_samples,\n",
    "        \"Accuracy(%)\": list_accuracy,\n",
    "    }\n",
    ")\n",
    "tab_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72914c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6537183746486072\n"
     ]
    }
   ],
   "source": [
    "tab = tab_result[tab_result[\"Num samples\"] >= 20]\n",
    "general_acc = round(tab[\"Accuracy(%)\"] * tab[\"Num samples\"])\n",
    "# print(general_acc)\n",
    "print(sum(general_acc) / sum(tab[\"Num samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed1b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_result.to_csv(\n",
    "    project_dir\n",
    "    + \"4_Outputs/Evaluation/\"\n",
    "    + data_name\n",
    "    + \"_Next_Activity_Tax_LSTM_eval.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
